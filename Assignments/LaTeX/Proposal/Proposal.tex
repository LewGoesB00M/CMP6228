% -------------------------------------------------------------------------------
% Establish page structure & font.
\documentclass[12pt]{report}

\usepackage[total={6.5in, 9in},
	left=1in,
	right=1in,
	top=1in,
	bottom=1in,]{geometry} % Page structure

\usepackage{graphicx} % Required for inserting images
\graphicspath{{../../.images}} % Any additional images I use (BCU logo, etc) are from here.

\usepackage[utf8]{inputenc} % UTF-8 encoding
\usepackage[T1]{fontenc} % T1 font
\usepackage{float}  % Allows for floats to be positioned using [H], which correctly
                    % positions them relative to their location within my LaTeX code.
\usepackage{subcaption}
\usepackage{csquotes}

% -------------------------------------------------------------------------------
% Declare biblatex with custom Harvard BCU styling for referencing.
\usepackage[
    useprefix=true,
    maxcitenames=2, % ! Using 3 causes an issue in the literature review due to name similarities.
    maxbibnames=99,
    style=authoryear,
    dashed=false, 
    natbib=true,
    url=false,
    backend=biber
]{biblatex}

\usepackage[british]{babel}

% Additional styling options to ensure Harvard referencing format.
\renewbibmacro*{volume+number+eid}{
    \printfield{volume}
    \setunit*{\addnbspace}
    \printfield{number}
    \setunit{\addcomma\space}
    \printfield{eid}}
\DeclareFieldFormat[article]{number}{\mkbibparens{#1}}

\addbibresource{Proposal.bib}

% -------------------------------------------------------------------------------
% To prevent "Chapter N" display for each chapter
\usepackage[compact]{titlesec}
\usepackage{wasysym}
\usepackage{import}

\titlespacing*{\chapter}{0pt}{-2cm}{0.5cm}
\titleformat{\chapter}[display]
{\normalfont\bfseries}{}{0pt}{\Huge}

% -------------------------------------------------------------------------------
% Custom macro to make an un-numbered footnote.

\newcommand\blfootnote[1]{
    \begingroup
    \renewcommand\thefootnote{}\footnote{#1}
    \addtocounter{footnote}{-1}
    \endgroup
}

% -------------------------------------------------------------------------------
% Fancy headers; used to show my name, BCU logo and current chapter for the page.
\usepackage{fancyhdr}
\usepackage{calc}
\pagestyle{fancy}

\setlength\headheight{37pt} % Set custom header height to fit the image.

\renewcommand{\chaptermark}[1]{%
    \markboth{#1}{}} % Include chapter name.


% Lewis Higgins - ID 22133848           [BCU LOGO]                [CHAPTER NAME]
\lhead{Lewis Higgins - ID 22133848~~~~~~~~~~~~~~~\includegraphics[width=1.75cm]{BCU}}
\fancyhead[R]{\leftmark}

% ------------------------------------------------------------------------------
% Used to add PDF hyperlinks for figures and the contents page.

\usepackage{hyperref}

\hypersetup{
    colorlinks=true,
    linkcolor=black,
    filecolor=magenta,
    urlcolor=blue,
    citecolor=black,
}

% ------------------------------------------------------------------------------
\usepackage{xcolor} 
\usepackage{colortbl}
\usepackage{longtable}
\usepackage{amssymb}
% ------------------------------------------------------------------------------
\usepackage{tcolorbox}
\newcommand{\para}{\vspace{7pt}\noindent}
% -------------------------------------------------------------------------------

\title{Leveraging Convolutional Neural Networks to identify Pneumonia}
\author{Lewis Higgins - Student ID 22133848}
\date{March 2025}

% -------------------------------------------------------------------------------

\begin{document}


\makeatletter
\begin{titlepage}
    \begin{center}
        \includegraphics[width=0.7\linewidth]{BCU}\\[4ex]
        {\huge \bfseries \@title}\\[2ex]
        {\large \bfseries  Project Proposal}\\[50ex]
        {\@author}\\[2ex]
        {CMP6228 - Deep Neural Networks}\\[2ex]
        {Module Coordinator: Khalid Ismail}\\[2ex]
        {Word count excluding figures, tables, references and appendices: XXXX / 1650}\\[10ex]
    \end{center}
\end{titlepage}
\makeatother
\thispagestyle{empty}
\newpage

% Page counter trick so that the contents page doesn't increment it.
\setcounter{page}{0}

\tableofcontents
\thispagestyle{empty}

\chapter*{Introduction}
\addcontentsline{toc}{chapter}{Introduction}

In this report, a novel solution is proposed to address a significant data science problem in the medical field, in the form of 
a deep neural network to accurately identify the presence of pneumonia from an image of a chest X-ray. To do so, this neural network 
will be trained on a publicly available dataset that has been previously seen across many publications, and advanced techniques 
for the model will be discussed.

\para This proposal will specifically cover the motivation behind this project before exploring related literature and previous works 
in great depth. To conclude, an optimal model will be proposed based on the knowledge extracted from these related works. 

% ! Weak. Come back to this probably at the very end.


\chapter{Motivation and objectives}

\section{Subject area}

Pneumonia is a lower respiratory tract infection (LRTI) commonly caused by viruses or bacteria wherein the alveoli of the lungs 
become clogged with pus and fluid, which can be life-threatening in people of any age, but especially in children and the elderly
\autocite{nhsPneumonia2017}. The World Health Organisation (WHO) state that pneumonia is the single largest infectious cause of death 
in children, killing 808,000 children under the age of 5 in 2017 \autocite{whoPneumonia}. Furthermore, even if pneumonia is survived during the 
initial infection, \textcite{allinsonEarlyChildhoodLower2023} studied that those who contract the condition as a child are 93\% more likely to die 
from respiratory diseases later in life than those who did not.

\para It is therefore imperative that recent technological advancements are leveraged for the quick diagnosis of the infection to allow swift 
treatment to avoid life-threatening consequences, both in the short-term and long-term. 

\section{Dataset choice}
The chosen dataset is sourced from the Mendeley data repository \autocite{mendeleydataLargeDatasetLabeled}, uploaded and created by  
\textcite[p.1127]{kermanyIdentifyingMedicalDiagnoses2018} in their research of the applications of neural networks for medical diagnoses.
The dataset contains 5,856 images of chest X-ray scans of children taken from the
Guangzhou Women and Children's Medical Center in China, and is 1.18GB in size. \textcite[p.e1]{kermanyIdentifyingMedicalDiagnoses2018} 
state that the data was heavily screened and scrutinized for confirmation before labelling, which was done by removing low quality or unreadable images,
and then consulting two expert physicians before labelling the images. The physicians' labelled set was then presented to a third expert, 
who confirmed their validity. Because of this, there is absolute certainty in the authenticity and validity of the data itself as well as its 
ground truth labels.
There are only two classes of images: those with 
pneumonia and those without, as depicted by Figures \ref{fig:SampleNORMAL} and \ref{fig:SamplePNEUMONIA}.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.4\textwidth]{Proposal/SampleNORMAL.jpeg}
    \caption{A sample image without pneumonia.\label{fig:SampleNORMAL}}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.5\textwidth]{Proposal/SamplePNEUMONIA.jpeg}
    \caption{A sample image with pneumonia.\label{fig:SamplePNEUMONIA}}
\end{figure}

\subsection{Potential issues}
The dataset has already been pre-emptively split into training and testing sets, which saves having to perform a manual split. 
However, the data itself is not immediately usable and will require further preprocessing before being used to train a model, namely due to the 
following issues:

\begin{itemize}
    \item Images are different resolutions.
    \begin{itemize}
        \item The sample images vary widely in resolution, with some being substantially higher than others.
        The neural network's input layer will be fixed in size, meaning all input data must be the 
        same size or the network will be unable to process it. This can be addressed programmatically using Keras to automatically resize 
        all images to a given resolution.
    \end{itemize}
    \item Class imbalance
    \begin{itemize}
        \item The training set contains 1,349 samples of patients without pneumonia, but 3,883 samples of patients with pneumonia.
        This will lead to the model favouring those with pneumonia rather than the underrepresented class of those without. This can be addressed 
        using the techniques discussed in Appendix A.
    \end{itemize}
\end{itemize}


% \begin{longtable}{ | p{0.25\textwidth} | p{0.65\textwidth} | }
%     \hline
%     \cellcolor{blue!25} Issue & \cellcolor{blue!25} Explanation \\
%     \hline
%     Images are not all the same resolution. & The neural network's input layer will be fixed in size, meaning all input data must be the 
%     same size or the network will be unable to process it. This can be addressed using Keras to automatically resize all images to a given 
%     resolution.\\
%     \hline
%     Class imbalance & The training set contains 1,349 samples of patients without pneumonia, but 3,883 samples of patients with pneumonia.
%     This will lead to the model favouring those with pneumonia rather than the underrepresented class of those without. This can be addressed 
%     using the techniques discussed in Appendix A.\\
%     \hline
%     \caption{The issues with the dataset before any preprocessing.}\label{tab:DatasetIssues}
% \end{longtable}

% ? 234 TestNorm, 390 TestPneu. 1349 TrainNorm, 3883 TrainPneu.

\pagebreak 

\section{Data science problem}
This dataset poses a clear data science problem pertaining to the binary classification of these images which will be addressed through the 
development of a convolutional neural network image classification model leveraging supervised learning. 
The ground truth is present within the dataset through its file structure\footnote{Because \textcite
{kermanyIdentifyingMedicalDiagnoses2018}'s work was not only on pneumonia, the Mendeley ZIP file contains two 
separate datasets. This proposal is only for the "chest\_xray" dataset.}, shown below:


\begin{verbatim}
    .
    `-- chest_xray/
        |-- test/
        |   |-- NORMAL/
        |   |   |-- NORMAL-4512-0001.jpeg
        |   |   |-- NORMAL-11419-0001.jpeg
        |   |   `-- ...234 more images
        |   `-- PNEUMONIA/
        |       |-- BACTERIA-40699-0001.jpeg
        |       |-- VIRUS-4190128-0001
        |       `-- ...388 more images
        `-- train/
            |-- NORMAL/
            |   |-- NORMAL-28501-0001.jpeg
            |   |-- NORMAL-32326-0001.jpeg
            |   `-- ...1347 more images
            `-- PNEUMONIA/
                |-- BACTERIA-7422-0001.jpeg
                |-- VIRUS-12220-0001.jpeg
                `-- ...3881 more images
\end{verbatim}

\noindent Files of the appropriate class are stored in the relevant subfolder\footnote{Shown file names are given as examples, and are not in the direct order they appear in the folders.}.
When this dataset is loaded, it will be possible to 
assign the relevant label to each image based on its subfolder of origin. Note that while there are separate files for bacterial and 
viral pneumonia, an analysis of other works using this dataset, seen in Chapter 2, indicated that this will not be an issue.

% "The aim is to develop a deep learning model to classify images into X classes."
% ? Describe the need for critical evaluation of the model.

% ! Footnote that the dataset contains multiple data science problems. I am only using "chest_xray", the 
% ! pneumonia identification problem.


\chapter{Related work}

% ! Added a ton of papers using this dataset to Zotero.
% ? You can use Litmaps to find more.

\section{Introduction}
This section of the report aims to demonstrate the main concepts
of related techniques that have been previously used to solve the problem 
through a thorough review of surrounding literature.

% ? What have other people done to solve it? How did they do it? 

\section{Traditional machine learning methods}
% ! This section was written while stressed-out and sleep-deprived and is likely absolute waffle that should be deleted.
Traditional machine learning methods such as Random Forests, K-Nearest Neighbours and Support 
Vector Machines have previously been leveraged for pneumonia classification as seen in the works of 
\textcite{ortiz-toroAutomaticDetectionPneumonia2022}. They state that leveraging these traditional approaches
alongside the creation of handcrafted textural features 'offers good performance with very low computational complexity',
as seen in their results wherein they attained an F1-Score
% ! Equation here for F1.
of 93\%.

\para However, leveraging traditional methods on detailed image datasets such as \textcite{kermanyIdentifyingMedicalDiagnoses2018}'s
relies upon manual feature engineering of textural features, which can unintentionally introduce bias. Dataset bias can significantly harm the generalisation capabilities of produced models \autocite{selvarajuGradCAMVisualExplanations2017}.
This is because it is possible that the new data given to a deployed model would differ from the preset features used on the original dataset,
which a biased model would be unable to accurately predict, unlike deep learning methods which can automatically interpret features without 
manual intervention.

\para Furthermore, some researchers such as \textcite{wangComparativeAnalysisImage2021} have leveraged both traditional and deep learning 
techniques on other unrelated datasets, wherein they discovered that the Support Vector Machine they used had an accuracy 10\% lower than 
a convolutional neural network on a large dataset, though actually had an accuracy 3\% higher on a smaller dataset. They also note that
deep learning methods have considerably longer training times than traditional counterparts.

\para SVMs in particular are the most commonly seen model in works using this dataset. SVMs aim to find the optimal hyperplane 
which separates one class from another. They are likely the most common due to their high performance and evaluation
metrics even when many dimensions are introduced, such as in image data. 

\begin{figure}[H]
    \centering
    \includegraphics[width=0.5\textwidth]{Proposal/SVM.png}
    \caption{A cursory overview of an SVM's functionality.\label{fig:SVM}}
\end{figure}


\section{Deep Neural Networks}
% * Neural networks themselves (Types [CNN, etc.])
Deep neural networks are the most heavily used methods for classification tasks with this dataset, which can be seen on both the 
dataset's Kaggle page \autocite{mooneyChestXRayImages2018}, and through a thorough literature search.

\para There are a wide variety of neural network 
types, though the most suitable and most commonly used neural network architecture across related literature\footnote{Specifically, the works of \textcite{elasnaouiDesignEnsembleDeep2021a,rajpurkarCheXNetRadiologistLevelPneumonia2017,sourabComparisonHybridDeep2022,stephenEfficientDeepLearning2019,umaribrahimConvolutionalNeuralNetwork2022b}} 
for image classifications such as the one proposed here is a Convolutional Neural Network (CNN).
CNNs are heavily used for image classification tasks across many fields, including for identifying pneumonia. A more detailed 
description of the functionality of a CNN can be found in Section \ref{sec:ModelArchitecture}, as this section instead details 
the accomplishments of other works with \textcite{kermanyIdentifyingMedicalDiagnoses2018}'s dataset.

\para \textcite{elasnaouiDesignEnsembleDeep2021a}'s work is one of the most informative\footnote{It should be noted that they used an altered dataset which they created from merging \textcite{kermanyIdentifyingMedicalDiagnoses2018}'s data with a COVID-19 dataset.}
%, and had their models also identify whether the pneumonia was from COVID or other causes.}, 
testing three different pretrained CNNs and then testing combinations of the three merged into different ensemble models. 
They tested implementations of pretrained InceptionResNet\_V2, MobileNet\_V2, and ResNet50 models, achieving F1-scores of 93.52, 91.62 and 93.47 
respectively. They also produced an ensemble model containing all three, which achieved their highest F1 score of 94.84. Their work clearly 
depicts the effectiveness of CNNs in classifying pneumonia.

\para Analysing the works of others published on the dataset's Kaggle page also follows this trend - CNNs are the most optimal choice for this 
particular classification task, with many achieving accuracies of at least 92\% with minimal overfitting. Many of these works cite the previously 
mentioned class imbalance, which \textcite{mathurPneumoniaDetectionUsing2020} and others solve with \textbf{data augmentation}. 

\newpage
\section{Data augmentation}



\chapter{Deep learning fundamentals}

% ? CNNs are good for image classification because they identify 'features' of an image rather than just the entire image.
% ? For instance, if I train my network to recognise images of the number 5, what if the 5 was in the corner of the image and not the middle?
% ? A CNN wouldn't struggle with this, and would likely still identify it where other networks may not.

% ? Apparently, CNNs overfitting on smaller datasets is a big issue, hence why he wanted you to find one of decent size (which you did).
% ? Dropout is one technique to address this, but another interesting one is data augmentation such as image rotation.

% ? He likely wants you to do augmentation. Consider the computational risk of doing that, though, given you have 6000 images.
% * It might not be too bad, actually. CIFAR10 is slow because it's 60k images.

Deep neural networks are a significant advancement in computing which build greatly upon traditional 
machine learning techniques especially in fields such as computer vision and image recognition. By leveraging newfound processing power 
typically found in high-end graphics cards, \textit{neural networks} formed of layers of neurons which replicate the functionality of 
the human mind can be created to solve problems at higher degrees of accuracy than ever before. A visualisation of a deep neural network 
is depicted in Figure \ref{fig:NeuralNetwork}.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{Proposal/NeuralNetworkCropped.png}
    \caption{A neural network with input, hidden and output layers \autocite{ibmWhatNeuralNetwork2021}.\label{fig:NeuralNetwork}}
\end{figure}

% \noindent The input layer consists of the amount of predictor features (such as the pixel colours in an image), which are then fed through 
% the model sequentially. The hidden layers are the backbone of the model where the actual processing occurs, with the training process dictating 
% the weight each node should have on the eventual prediction (the 'importance' of each node, put simply). After the hidden layers, the output 
% layer will consist of nodes equal to the amount of classes in a classification problem. 

\section{Convolutional Neural Networks (CNNs)}


\chapter{Proposed model}
"This section should demonstrate the suitability of
the proposed solution in solving the data science problem"

\section{Architecture}\label{sec:ModelArchitecture}

% ? The model proposed here doesn't *need* to be the one you eventually use, but you should.

% ! Add the word count to the title page before submission.

% ? When you submit your code, don't use your coloured comments like these.

\addcontentsline{toc}{chapter}{Bibliography}

% ? Prevents bibliography overflowing hbox at the expense of it taking up more lines on the page.
\emergencystretch=1em
\printbibliography

\include{AppendixA}

\end{document}