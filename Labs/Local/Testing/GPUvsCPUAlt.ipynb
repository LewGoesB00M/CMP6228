{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-02 00:48:25.517591: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1738457305.529199    1632 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1738457305.532678    1632 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-02-02 00:48:25.544769: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 GPU device(s) have been found on your notebook :\n",
      "* GPU n째0 whose name is \"/device:GPU:0\"\n",
      "\n",
      "1 CPU device(s) have been found on your notebook :\n",
      "* CPU n째0 whose name is \"/device:CPU:0\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1738457308.499026    1632 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5137 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060 Ti, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "# Get the list of all logical GPU device on your notebook\n",
    "GPU_DEVICES = tf.config.list_logical_devices('GPU')\n",
    "# Get the list of all logical CPU device on your notebook\n",
    "CPU_DEVICES = tf.config.list_logical_devices('CPU')\n",
    "# Keep only the names of each GPU devices\n",
    "GPU_DEVICES_NAMES = [x.name for x in GPU_DEVICES]\n",
    "# Keep only the names of each CPU devices\n",
    "CPU_DEVICES_NAMES = [x.name for x in CPU_DEVICES]\n",
    "# The number of GPU devices\n",
    "GPU_DEVICES_NB = len(GPU_DEVICES)\n",
    "# The number of CPU devices\n",
    "CPU_DEVICES_NB = len(CPU_DEVICES)\n",
    "\n",
    "if GPU_DEVICES_NB == 0:\n",
    "    raise SystemError('No GPU device found')\n",
    "else:\n",
    "    print(f'{GPU_DEVICES_NB} GPU device(s) have been found on your notebook :')\n",
    "\n",
    "for nb in range(GPU_DEVICES_NB):\n",
    "    gpu_name = GPU_DEVICES_NAMES[nb]\n",
    "    print(f'* GPU n째{nb} whose name is \"{gpu_name}\"')\n",
    "    \n",
    "print('')\n",
    "    \n",
    "if CPU_DEVICES_NB == 0:\n",
    "    raise SystemError('No CPU device found')\n",
    "else:\n",
    "    print(f'{CPU_DEVICES_NB} CPU device(s) have been found on your notebook :')\n",
    "\n",
    "for nb in range(CPU_DEVICES_NB):\n",
    "    cpu_name = CPU_DEVICES_NAMES[nb]\n",
    "    print(f'* CPU n째{nb} whose name is \"{cpu_name}\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_multiply(vector_length):\n",
    "    vector_1 = tf.random.normal(vector_length)\n",
    "    vector_2 = tf.random.normal(vector_length)\n",
    "    return vector_1 * vector_2\n",
    "\n",
    "def gpu_operation(vector_length):\n",
    "    # If you have several GPU you can select the one to use by changing the used index of GPU_DEVICES_NAMES\n",
    "    with tf.device(GPU_DEVICES_NAMES[0]):\n",
    "        random_multiply(vector_length)\n",
    "        \n",
    "def cpu_operation(vector_length):\n",
    "    # If you have several CPU you can select the one to use by changing the used index of GPU_DEVICES_NAMES\n",
    "    with tf.device(CPU_DEVICES_NAMES[0]):\n",
    "        random_multiply(vector_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Operations on vector of length 1 are 0.2673338796696081x faster on GPU than CPU\n",
      "Operations on vector of length 10 are 0.8505639143882999x faster on GPU than CPU\n",
      "Operations on vector of length 100 are 0.43602837228543667x faster on GPU than CPU\n",
      "Operations on vector of length 1000 are 0.48919103232787275x faster on GPU than CPU\n",
      "Operations on vector of length 10000 are 1.5784563388358728x faster on GPU than CPU\n",
      "Operations on vector of length 100000 are 2.923624943511755x faster on GPU than CPU\n",
      "Operations on vector of length 1000000 are 16.73305110986887x faster on GPU than CPU\n",
      "Operations on vector of length 10000000 are 141.4996162494821x faster on GPU than CPU\n",
      "Operations on vector of length 100000000 are 1160.2650143649378x faster on GPU than CPU\n"
     ]
    }
   ],
   "source": [
    "import timeit\n",
    "\n",
    "# We run each op once to warm up; see: https://stackoverflow.com/a/45067900\n",
    "cpu_operation([1])\n",
    "gpu_operation([1])\n",
    "\n",
    "for i in range(9):\n",
    "    vector_length = pow(10, i)\n",
    "    cpu_time = timeit.timeit(f'cpu_operation([{vector_length}])', number=20, setup=\"from __main__ import cpu_operation\")\n",
    "    gpu_time = timeit.timeit(f'gpu_operation([{vector_length}])', number=20, setup=\"from __main__ import gpu_operation\")\n",
    "    print(f'Operations on vector of length {vector_length} are {cpu_time/gpu_time}x faster on GPU than CPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all this has really proven is that the Colab GPUs are better than yours and this was entirely a waste of time.\n",
    "# i guess it got me to learn WSL and Docker?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
