{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Lab 8 - Transfer learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lzfZSxtkNDl9"
      },
      "source": [
        "## Shallow mode"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5GeFBY_BNDl_"
      },
      "source": [
        "### Imports and vars"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Lpz3vXK8NDl_"
      },
      "outputs": [],
      "source": [
        "from keras.datasets import cifar10\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.optimizers import SGD, Adam, RMSprop\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from keras.applications.vgg16 import VGG16, preprocess_input\n",
        "from keras import models, layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "yKPskIazNDmA"
      },
      "outputs": [],
      "source": [
        "# --- Constants ---\n",
        "IMG_ROWS = 32\n",
        "IMG_COLS = 32\n",
        "IMG_CHANNELS = 3\n",
        "BATCH_SIZE = 128\n",
        "NB_EPOCH = 20\n",
        "NB_CLASSES = 10\n",
        "VALIDATION_SPLIT = 0.2\n",
        "OPTIM = RMSprop()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nMqJlx_SNDmB",
        "outputId": "d7bce334-f837-4793-e6e2-0d3dcea9a44b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "\u001b[1m170498071/170498071\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 0us/step\n",
            "X_train shape: (50000, 32, 32, 3)\n",
            "50000 train samples\n",
            "10000 test samples\n"
          ]
        }
      ],
      "source": [
        "# --- Load CIFAR-10 ---\n",
        "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
        "print('X_train shape:', X_train.shape) # (50000, 32, 32, 3)\n",
        "print(X_train.shape[0], 'train samples')\n",
        "print(X_test.shape[0], 'test samples')\n",
        "Y_train = to_categorical(y_train, NB_CLASSES)\n",
        "Y_test = to_categorical(y_test, NB_CLASSES)\n",
        "X_train = X_train.astype('float32') / 255.0\n",
        "X_test = X_test.astype('float32') / 255.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P2chd41INDmC"
      },
      "source": [
        "### Model building"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V2M1QauwNDmC",
        "outputId": "9afa4212-784a-40f9-ac02-f230b10a104c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m58889256/58889256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        }
      ],
      "source": [
        "# --- Build the model with pre-trained VGG16 convolutional base ---\n",
        "conv_base = VGG16(weights='imagenet',\n",
        "                  include_top=False,\n",
        "                  input_shape=(IMG_ROWS, IMG_COLS, IMG_CHANNELS))\n",
        "\n",
        "# Freeze the convolutional base\n",
        "conv_base.trainable = False\n",
        "# ? Seems that this'll keep the model's pretraining (the 'convolutional base').\n",
        "\n",
        "model = models.Sequential()\n",
        "model.add(conv_base)\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(256, activation='relu'))\n",
        "model.add(layers.Dense(NB_CLASSES, activation='softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=OPTIM,\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HH_OtilPNDmC"
      },
      "source": [
        "### Training and evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SBUdM2h1NDmD",
        "outputId": "3f579b48-8ca4-4baf-c9d1-2ff5fc349b3e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 45ms/step - accuracy: 0.4296 - loss: 1.6333 - val_accuracy: 0.5531 - val_loss: 1.2954\n",
            "Epoch 2/20\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 24ms/step - accuracy: 0.5591 - loss: 1.2637 - val_accuracy: 0.5603 - val_loss: 1.2468\n",
            "Epoch 3/20\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 25ms/step - accuracy: 0.5908 - loss: 1.1773 - val_accuracy: 0.5635 - val_loss: 1.2250\n",
            "Epoch 4/20\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 28ms/step - accuracy: 0.6023 - loss: 1.1339 - val_accuracy: 0.5884 - val_loss: 1.1894\n",
            "Epoch 5/20\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 25ms/step - accuracy: 0.6149 - loss: 1.1000 - val_accuracy: 0.6003 - val_loss: 1.1554\n",
            "Epoch 6/20\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 28ms/step - accuracy: 0.6256 - loss: 1.0690 - val_accuracy: 0.5988 - val_loss: 1.1584\n",
            "Epoch 7/20\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 29ms/step - accuracy: 0.6369 - loss: 1.0378 - val_accuracy: 0.5973 - val_loss: 1.1505\n",
            "Epoch 8/20\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 25ms/step - accuracy: 0.6454 - loss: 1.0114 - val_accuracy: 0.5788 - val_loss: 1.2084\n",
            "Epoch 9/20\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 26ms/step - accuracy: 0.6557 - loss: 0.9876 - val_accuracy: 0.6035 - val_loss: 1.1502\n",
            "Epoch 10/20\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 25ms/step - accuracy: 0.6648 - loss: 0.9670 - val_accuracy: 0.6080 - val_loss: 1.1346\n",
            "Epoch 11/20\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 26ms/step - accuracy: 0.6706 - loss: 0.9375 - val_accuracy: 0.6159 - val_loss: 1.1219\n",
            "Epoch 12/20\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 25ms/step - accuracy: 0.6817 - loss: 0.9165 - val_accuracy: 0.6119 - val_loss: 1.1318\n",
            "Epoch 13/20\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 28ms/step - accuracy: 0.6844 - loss: 0.9012 - val_accuracy: 0.6054 - val_loss: 1.1653\n",
            "Epoch 14/20\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - accuracy: 0.6963 - loss: 0.8784 - val_accuracy: 0.6047 - val_loss: 1.1666\n",
            "Epoch 15/20\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 29ms/step - accuracy: 0.7060 - loss: 0.8551 - val_accuracy: 0.6021 - val_loss: 1.1633\n",
            "Epoch 16/20\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 25ms/step - accuracy: 0.7100 - loss: 0.8394 - val_accuracy: 0.6062 - val_loss: 1.1613\n",
            "Epoch 17/20\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 29ms/step - accuracy: 0.7186 - loss: 0.8114 - val_accuracy: 0.6101 - val_loss: 1.1569\n",
            "Epoch 18/20\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 25ms/step - accuracy: 0.7168 - loss: 0.8101 - val_accuracy: 0.6187 - val_loss: 1.1419\n",
            "Epoch 19/20\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 29ms/step - accuracy: 0.7253 - loss: 0.7849 - val_accuracy: 0.6191 - val_loss: 1.1316\n",
            "Epoch 20/20\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 26ms/step - accuracy: 0.7295 - loss: 0.7693 - val_accuracy: 0.6193 - val_loss: 1.1295\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7aa9b973ccd0>"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# --- Train ---\n",
        "model.fit(X_train, Y_train,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=NB_EPOCH,\n",
        "          validation_split=VALIDATION_SPLIT,\n",
        "          verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FVcW2RodNDmE",
        "outputId": "adf1f109-30f5-45b6-f1ff-42fb3891f4a8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.6185 - loss: 1.1327\n",
            "Test score: 1.1447113752365112\n",
            "Test accuracy: 0.6136000156402588\n"
          ]
        }
      ],
      "source": [
        "score = model.evaluate(X_test, Y_test,\n",
        "                       batch_size=BATCH_SIZE,\n",
        "                       verbose=1)\n",
        "\n",
        "print(\"Test score:\", score[0])\n",
        "print(\"Test accuracy:\", score[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GfZjGOOQNDmF"
      },
      "source": [
        "## Fine-tuning mode"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D9xhQS1mNDmG"
      },
      "source": [
        "Fine-tuning mode unfreezes some of the top layers of the convolutional base which it uses for feature extraction, allowing them to learn features in the new data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e-giceOwNDmG"
      },
      "source": [
        "### Imports and vars"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "MexlBUP4NDmH"
      },
      "outputs": [],
      "source": [
        "from keras.datasets import cifar10\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.optimizers import SGD, Adam, RMSprop\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.applications.vgg16 import preprocess_input\n",
        "from keras import models, layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "RSVm1EJMNDmH"
      },
      "outputs": [],
      "source": [
        "# --- Constants ---\n",
        "IMG_ROWS = 32\n",
        "IMG_COLS = 32\n",
        "IMG_CHANNELS = 3\n",
        "BATCH_SIZE = 128\n",
        "NB_EPOCH = 20\n",
        "NB_CLASSES = 10\n",
        "VALIDATION_SPLIT = 0.2\n",
        "OPTIM = RMSprop()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Eb9guoKNDmH",
        "outputId": "f609c7ce-693b-49c3-a842-c0d94c5095d9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "\u001b[1m170498071/170498071\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 0us/step\n",
            "X_train shape: (50000, 32, 32, 3)\n",
            "50000 train samples\n",
            "10000 test samples\n"
          ]
        }
      ],
      "source": [
        "# --- Load CIFAR-10 ---\n",
        "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
        "print('X_train shape:', X_train.shape)\n",
        "print(X_train.shape[0], 'train samples')\n",
        "print(X_test.shape[0], 'test samples')\n",
        "Y_train = to_categorical(y_train, NB_CLASSES)\n",
        "Y_test = to_categorical(y_test, NB_CLASSES)\n",
        "X_train = X_train.astype('float32') / 255.0\n",
        "X_test = X_test.astype('float32') / 255.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IfkquUhWNDmI"
      },
      "source": [
        "### Freezing and unfreezing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AsZhQtCHNDmI",
        "outputId": "ef3876f7-1bdb-402c-fbc4-6aeffa0f0d46"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m58889256/58889256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 0us/step\n"
          ]
        }
      ],
      "source": [
        "# --- Build the model: VGG16 as convolutional base ---\n",
        "conv_base = VGG16(weights='imagenet',\n",
        "                  include_top=False,\n",
        "                  input_shape=(IMG_ROWS, IMG_COLS, IMG_CHANNELS))\n",
        "\n",
        "# Initially freeze the entire base\n",
        "conv_base.trainable = True\n",
        "set_trainable = False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p7RfXfqKNDmI"
      },
      "source": [
        "You can **choose** which layers to unfreeze."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "QHYPcwhqNDmI"
      },
      "outputs": [],
      "source": [
        "# Example rule: unfreeze from 'block5_conv1' onward\n",
        "for layer in conv_base.layers:\n",
        "    if layer.name == 'block5_conv1':\n",
        "        set_trainable = True\n",
        "        # When we get to here, set trainable to true.\n",
        "        # This makes all following layers trainable.\n",
        "\n",
        "    if set_trainable:\n",
        "        layer.trainable = True\n",
        "    else:\n",
        "        layer.trainable = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5OrxVGWWNDmJ",
        "outputId": "82f77b52-967c-4352-8685-4913c447452e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "input_layer False\n",
            "block1_conv1 False\n",
            "block1_conv2 False\n",
            "block1_pool False\n",
            "block2_conv1 False\n",
            "block2_conv2 False\n",
            "block2_pool False\n",
            "block3_conv1 False\n",
            "block3_conv2 False\n",
            "block3_conv3 False\n",
            "block3_pool False\n",
            "block4_conv1 False\n",
            "block4_conv2 False\n",
            "block4_conv3 False\n",
            "block4_pool False\n",
            "block5_conv1 True\n",
            "block5_conv2 True\n",
            "block5_conv3 True\n",
            "block5_pool True\n"
          ]
        }
      ],
      "source": [
        "# Check trainable layers\n",
        "for layer in conv_base.layers:\n",
        "    print(layer.name, layer.trainable)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IAZRlQxiNDmJ"
      },
      "source": [
        "### Model building"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "7C107coDNDmJ"
      },
      "outputs": [],
      "source": [
        "model = models.Sequential()\n",
        "model.add(conv_base)\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(256, activation='relu'))\n",
        "model.add(layers.Dense(NB_CLASSES, activation='softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=OPTIM,\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g06oYo96NDmJ"
      },
      "source": [
        "### Training and evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3d231idWNDmJ",
        "outputId": "1e2ecaed-7fdb-48dd-d7fb-3f0ebbbf44c7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 51ms/step - accuracy: 0.0996 - loss: 2.4435 - val_accuracy: 0.0977 - val_loss: 2.3027\n",
            "Epoch 2/20\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 32ms/step - accuracy: 0.1005 - loss: 2.3026 - val_accuracy: 0.0980 - val_loss: 2.3027\n",
            "Epoch 3/20\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 28ms/step - accuracy: 0.0999 - loss: 2.3027 - val_accuracy: 0.0980 - val_loss: 2.3028\n",
            "Epoch 4/20\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 32ms/step - accuracy: 0.0991 - loss: 2.3026 - val_accuracy: 0.0952 - val_loss: 2.3028\n",
            "Epoch 5/20\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 32ms/step - accuracy: 0.1004 - loss: 2.3026 - val_accuracy: 0.0952 - val_loss: 2.3027\n",
            "Epoch 6/20\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 32ms/step - accuracy: 0.0975 - loss: 2.3027 - val_accuracy: 0.0952 - val_loss: 2.3027\n",
            "Epoch 7/20\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 29ms/step - accuracy: 0.0946 - loss: 2.3027 - val_accuracy: 0.0952 - val_loss: 2.3028\n",
            "Epoch 8/20\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 32ms/step - accuracy: 0.1026 - loss: 2.3026 - val_accuracy: 0.0952 - val_loss: 2.3027\n",
            "Epoch 9/20\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 29ms/step - accuracy: 0.1011 - loss: 2.3026 - val_accuracy: 0.0952 - val_loss: 2.3027\n",
            "Epoch 10/20\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 33ms/step - accuracy: 0.1017 - loss: 2.3026 - val_accuracy: 0.0980 - val_loss: 2.3027\n",
            "Epoch 11/20\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 30ms/step - accuracy: 0.1005 - loss: 2.3026 - val_accuracy: 0.0980 - val_loss: 2.3028\n",
            "Epoch 12/20\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 30ms/step - accuracy: 0.1012 - loss: 2.3027 - val_accuracy: 0.0952 - val_loss: 2.3028\n",
            "Epoch 13/20\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 30ms/step - accuracy: 0.1003 - loss: 2.3027 - val_accuracy: 0.0980 - val_loss: 2.3028\n",
            "Epoch 14/20\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 33ms/step - accuracy: 0.0963 - loss: 2.3026 - val_accuracy: 0.0952 - val_loss: 2.3027\n",
            "Epoch 15/20\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 33ms/step - accuracy: 0.1009 - loss: 2.3026 - val_accuracy: 0.0952 - val_loss: 2.3027\n",
            "Epoch 16/20\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 30ms/step - accuracy: 0.0980 - loss: 2.3027 - val_accuracy: 0.0952 - val_loss: 2.3028\n",
            "Epoch 17/20\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 33ms/step - accuracy: 0.1003 - loss: 2.3026 - val_accuracy: 0.0952 - val_loss: 2.3027\n",
            "Epoch 18/20\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 30ms/step - accuracy: 0.0993 - loss: 2.3026 - val_accuracy: 0.0997 - val_loss: 2.3027\n",
            "Epoch 19/20\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 29ms/step - accuracy: 0.0968 - loss: 2.3027 - val_accuracy: 0.0997 - val_loss: 2.3027\n",
            "Epoch 20/20\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 29ms/step - accuracy: 0.0979 - loss: 2.3027 - val_accuracy: 0.0952 - val_loss: 2.3028\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7937e12c63d0>"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.fit(X_train, Y_train,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=NB_EPOCH,\n",
        "          validation_split=VALIDATION_SPLIT,\n",
        "          verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PjjYYhPyNDmK",
        "outputId": "71b061a2-69d6-4b77-8beb-aaa7b0727400"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.1009 - loss: 2.3026\n",
            "Test score: 2.3026232719421387\n",
            "Test accuracy: 0.10000000149011612\n"
          ]
        }
      ],
      "source": [
        "score = model.evaluate(X_test, Y_test,\n",
        "                       batch_size=BATCH_SIZE,\n",
        "                       verbose=1)\n",
        "\n",
        "print(\"Test score:\", score[0])\n",
        "print(\"Test accuracy:\", score[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bFilAg7BP0Ep"
      },
      "source": [
        "# Shallow yielded much better results than fine-tuned in this scenario. Perhaps you should try **both**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YBhuFf_OTnqW"
      },
      "source": [
        "Consider it like shallow mode splits the model into two stages, with the original pretrained convolutional base staying independent and then passed into a classifier, whereas finetuned extends the existing convolutional base."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
