{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ensure all other Jupyter kernels are stopped when running GPU-accelerated labs.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Labs can also run on your laptop CPU, albeit at slightly reduced speed (but less than you might expect).**\n",
    "\n",
    "\n",
    "**If performed on laptop, charger must be connected (4x slower if on battery)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.11.1\n",
      "Detected devices: [PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras.datasets import boston_housing\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from etils import ecolab # ? Collapsible text output.\n",
    "\n",
    "np.random.seed(1671) # Reproducibility, same seed used in lab sheet.\n",
    "\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "print(\"Detected devices:\", tf.config.list_physical_devices())\n",
    "# assert tf.test.is_built_with_cuda() \n",
    "# ? Throws an error if CUDA isn't working properly (GPU disconnected)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "(trainData, trainTargets), (testData, testTargets) = boston_housing.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = trainData.mean(axis=0)\n",
    "trainData -= mean\n",
    "std = trainData.std(axis=0)\n",
    "trainData /= std\n",
    "testData -= mean\n",
    "testData /= std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildModel():\n",
    "    model = models.Sequential()\n",
    "    \n",
    "    model.add(layers.Dense(64, activation = \"relu\", \n",
    "                           input_shape = (trainData.shape[1],)))\n",
    "    model.add(layers.Dense(64, activation = \"relu\"))\n",
    "    model.add(layers.Dense(1))\n",
    "    \n",
    "    model.compile(optimizer = \"rmsprop\", loss = \"mse\", metrics = [\"mae\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Will be appended to in order to hold all model metrics.\n",
    "allScores = []\n",
    "\n",
    "def kFold(k, numEpochs, trainData = trainData):\n",
    "    numValSamples = len(trainData) // k\n",
    "    \n",
    "    for i in range(k):\n",
    "        print(\"Processing fold\", i + 1)\n",
    "        valData = trainData[i * numValSamples: (i + 1) * numValSamples] \n",
    "        valTargets = trainTargets[i * numValSamples: (i + 1) * numValSamples]\n",
    "        partialTrainData = np.concatenate(\n",
    "            [trainData[: i * numValSamples], \n",
    "             trainData[(i + 1) * numValSamples:]],\n",
    "            axis = 0\n",
    "        ) \n",
    "        partialTrainTargets = np.concatenate(\n",
    "            [trainTargets[: i * numValSamples], \n",
    "             trainTargets[(i + 1) * numValSamples:]],\n",
    "            axis = 0\n",
    "        ) \n",
    "        \n",
    "        model = buildModel()\n",
    "        \n",
    "        model.fit(partialTrainData, partialTrainTargets, epochs = numEpochs,\n",
    "                  batch_size = 1, verbose = 1)\n",
    "        \n",
    "        valMSE, valMAE = model.evaluate(valData, valTargets)\n",
    "        allScores.append(valMAE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc53e20d4fe44f1296911d01637bc991",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Accordion(children=(Output(),), titles=('',))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# ? Collapses output so that this notebook can be scrolled much easier.\n",
    "with ecolab.collapse():\n",
    "    kFold(k = 4, numEpochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0 MAE: 1.9313733577728271\n",
      "Fold 1 MAE: 2.923966884613037\n",
      "Fold 2 MAE: 2.489597797393799\n",
      "Fold 3 MAE: 2.3872668743133545\n",
      "Overall MAE: 2.4330512285232544\n"
     ]
    }
   ],
   "source": [
    "for i, score in enumerate(allScores):\n",
    "    print(f\"Fold {i} MAE: {score}\")\n",
    "    \n",
    "print(f\"Overall MAE: {np.mean(allScores)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ? The KFold function created earlier can be updated to track per-epoch scores.\n",
    "allMAEHistories = []\n",
    "\n",
    "# ? Also refreshing the allScores.\n",
    "allScores = []\n",
    "\n",
    "def kFold(k, numEpochs, trainData = trainData):\n",
    "    numValSamples = len(trainData) // k\n",
    "    \n",
    "    for i in range(k):\n",
    "        print(\"Processing fold\", i + 1)\n",
    "        valData = trainData[i * numValSamples: (i + 1) * numValSamples] \n",
    "        valTargets = trainTargets[i * numValSamples: (i + 1) * numValSamples]\n",
    "        partialTrainData = np.concatenate(\n",
    "            [trainData[: i * numValSamples], \n",
    "             trainData[(i + 1) * numValSamples:]],\n",
    "            axis = 0\n",
    "        ) \n",
    "        partialTrainTargets = np.concatenate(\n",
    "            [trainTargets[: i * numValSamples], \n",
    "             trainTargets[(i + 1) * numValSamples:]],\n",
    "            axis = 0\n",
    "        ) \n",
    "        \n",
    "        model = buildModel()\n",
    "        \n",
    "        # ! New functionality below. Model now uses validation data and \n",
    "        # ! tracks MAEs across all epochs, appending them to allMAEHistories list.\n",
    "        history = model.fit(partialTrainData, partialTrainTargets, \n",
    "                            validation_data = (valData, valTargets),\n",
    "                            epochs = numEpochs, batch_size = 1, verbose = 1)\n",
    "        \n",
    "        maeHistory = history.history[\"val_mae\"]\n",
    "        allMAEHistories.append(maeHistory)\n",
    "        \n",
    "        # ? Also get the per-fold scores as before.\n",
    "        valMSE, valMAE = model.evaluate(valData, valTargets)\n",
    "        allScores.append(valMAE)\n",
    "        \n",
    "    averageMAEHistory = [np.mean([x[i] # ? Get the mean\n",
    "                        for x in allMAEHistories]) # ? of all MAEs\n",
    "                        for i in range(numEpochs)] # ? across all epochs.\n",
    "    \n",
    "    plt.plot(range(1, len(averageMAEHistory) + 1), averageMAEHistory)\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Validation MAE')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81f0228f6eb242eebe54f8eedb08cf1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Accordion(children=(Output(),), titles=('',))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# ? Collapses output so that this notebook can be scrolled much easier.\n",
    "with ecolab.collapse():\n",
    "    kFold(k = 4, numEpochs = 3)\n",
    "    # ? 200 epochs was specified in the lab sheet but it takes approx 5min30sec."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The graph will look like a very sharp decrease in loss followed by heavy fluctuations across epochs (up/down/up/down etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0 average MAE: 2.4219443798065186\n",
      "Fold 1 average MAE: 2.9383139610290527\n",
      "Fold 2 average MAE: 2.779630661010742\n",
      "Fold 3 average MAE: 2.814145565032959\n",
      "Average of all folds: 2.738508641719818\n"
     ]
    }
   ],
   "source": [
    "for i, score in enumerate(allScores):\n",
    "    print(f\"Fold {i} average MAE: {score}\")\n",
    "    \n",
    "print(f\"Average of all folds: {np.mean(allScores)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ! These last cells were rushed due to time running out in the lab.\n",
    "\n",
    "# Letâ€™s use k-fold cross-validation and get the loss error for\n",
    "# the training and validation sets for visualisation\n",
    "allMAEHistories = []\n",
    "allMAEHistoriesTrain = [] # this is for the training curve\n",
    "\n",
    "def kFold(k, numEpochs, trainData = trainData):\n",
    "    numValSamples = len(trainData) // k\n",
    "    \n",
    "    for i in range(k):\n",
    "        print(\"Processing fold\", i + 1)\n",
    "        valData = trainData[i * numValSamples: (i + 1) * numValSamples] \n",
    "        valTargets = trainTargets[i * numValSamples: (i + 1) * numValSamples]\n",
    "        partialTrainData = np.concatenate(\n",
    "            [trainData[: i * numValSamples], \n",
    "             trainData[(i + 1) * numValSamples:]],\n",
    "            axis = 0\n",
    "        ) \n",
    "        partialTrainTargets = np.concatenate(\n",
    "            [trainTargets[: i * numValSamples], \n",
    "             trainTargets[(i + 1) * numValSamples:]],\n",
    "            axis = 0\n",
    "        ) \n",
    "        \n",
    "        model = buildModel()\n",
    "        \n",
    "        history = model.fit(partialTrainData, partialTrainTargets, \n",
    "                            validation_data = (valData, valTargets),\n",
    "                            epochs = numEpochs, batch_size = 1, verbose = 1)\n",
    "        \n",
    "        maeHistory = history.history[\"val_mae\"]\n",
    "        allMAEHistories.append(maeHistory)\n",
    "        \n",
    "        maeTrainHistory = history.history[\"loss\"]\n",
    "        allMAEHistoriesTrain.append(maeTrainHistory)\n",
    "        \n",
    "        \n",
    "    averageMAEHistory = [np.mean([x[i] \n",
    "                            for x in allMAEHistories]) \n",
    "                            for i in range(numEpochs)]\n",
    "    averageMAEHistoryTrain = [np.mean([x[i] \n",
    "                            for x in allMAEHistoriesTrain]) \n",
    "                            for i in range(numEpochs)]\n",
    "    \n",
    "    plt.plot(range(1, len(averageMAEHistory) + 1),\n",
    "            averageMAEHistory, 'r', label = 'validation loss')\n",
    "    plt.plot(range(1, len(averageMAEHistoryTrain) + 1),\n",
    "            averageMAEHistoryTrain, 'b', label = 'training loss')\n",
    "    \n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing fold 1\n",
      "Epoch 1/25\n",
      "303/303 [==============================] - 1s 2ms/step - loss: 205.6472 - mae: 10.8201 - val_loss: 35.0808 - val_mae: 3.9436\n",
      "Epoch 2/25\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 28.5402 - mae: 3.5877 - val_loss: 21.8692 - val_mae: 2.9339\n",
      "Epoch 3/25\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 20.0181 - mae: 3.0289 - val_loss: 16.8216 - val_mae: 2.5931\n",
      "Epoch 4/25\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 16.6317 - mae: 2.7768 - val_loss: 15.5566 - val_mae: 2.4647\n",
      "Epoch 5/25\n",
      "303/303 [==============================] - 1s 2ms/step - loss: 14.6760 - mae: 2.5878 - val_loss: 17.1614 - val_mae: 2.8130\n",
      "Epoch 6/25\n",
      "303/303 [==============================] - 1s 2ms/step - loss: 14.0933 - mae: 2.4604 - val_loss: 11.2631 - val_mae: 2.3285\n",
      "Epoch 7/25\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 13.5082 - mae: 2.4435 - val_loss: 11.2712 - val_mae: 2.4261\n",
      "Epoch 8/25\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 12.4210 - mae: 2.3098 - val_loss: 10.9136 - val_mae: 2.2545\n",
      "Epoch 9/25\n",
      "303/303 [==============================] - 0s 2ms/step - loss: 12.3766 - mae: 2.3528 - val_loss: 11.1096 - val_mae: 2.2074\n",
      "Epoch 10/25\n",
      "303/303 [==============================] - 0s 2ms/step - loss: 12.7600 - mae: 2.2902 - val_loss: 9.8701 - val_mae: 2.0270\n",
      "Epoch 11/25\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 11.8685 - mae: 2.2427 - val_loss: 11.4150 - val_mae: 2.4986\n",
      "Epoch 12/25\n",
      "303/303 [==============================] - 1s 2ms/step - loss: 11.6645 - mae: 2.2557 - val_loss: 10.9715 - val_mae: 2.2004\n",
      "Epoch 13/25\n",
      "303/303 [==============================] - 1s 2ms/step - loss: 11.2102 - mae: 2.1823 - val_loss: 11.6374 - val_mae: 2.3394\n",
      "Epoch 14/25\n",
      "303/303 [==============================] - 0s 2ms/step - loss: 10.9138 - mae: 2.1663 - val_loss: 9.3138 - val_mae: 2.0457\n",
      "Epoch 15/25\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 10.5783 - mae: 2.1437 - val_loss: 9.1714 - val_mae: 1.9562\n",
      "Epoch 16/25\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 10.2834 - mae: 2.1241 - val_loss: 8.3242 - val_mae: 2.0558\n",
      "Epoch 17/25\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 10.3456 - mae: 2.1628 - val_loss: 8.6465 - val_mae: 2.0482\n",
      "Epoch 18/25\n",
      "303/303 [==============================] - 0s 2ms/step - loss: 10.0096 - mae: 2.1087 - val_loss: 8.5272 - val_mae: 2.0420\n",
      "Epoch 19/25\n",
      "303/303 [==============================] - 1s 2ms/step - loss: 9.3659 - mae: 2.0761 - val_loss: 9.1813 - val_mae: 2.0698\n",
      "Epoch 20/25\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 9.7887 - mae: 2.0749 - val_loss: 10.1075 - val_mae: 2.4984\n",
      "Epoch 21/25\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 9.4369 - mae: 2.0185 - val_loss: 8.5735 - val_mae: 1.9286\n",
      "Epoch 22/25\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 9.7634 - mae: 2.0615 - val_loss: 8.0928 - val_mae: 1.9847\n",
      "Epoch 23/25\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 8.8170 - mae: 2.0489 - val_loss: 8.1579 - val_mae: 1.9278\n",
      "Epoch 24/25\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 9.2944 - mae: 2.0401 - val_loss: 7.5253 - val_mae: 1.9748\n",
      "Epoch 25/25\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 9.2226 - mae: 2.0531 - val_loss: 7.8077 - val_mae: 1.9949\n",
      "Processing fold 2\n",
      "Epoch 1/25\n",
      "303/303 [==============================] - 1s 2ms/step - loss: 189.7443 - mae: 10.1179 - val_loss: 30.2130 - val_mae: 4.1011\n",
      "Epoch 2/25\n",
      "303/303 [==============================] - 1s 2ms/step - loss: 28.0357 - mae: 3.6548 - val_loss: 19.0466 - val_mae: 3.1501\n",
      "Epoch 3/25\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 21.4602 - mae: 2.9968 - val_loss: 16.4777 - val_mae: 2.9379\n",
      "Epoch 4/25\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 17.6795 - mae: 2.6828 - val_loss: 15.3117 - val_mae: 2.8287\n",
      "Epoch 5/25\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 15.0484 - mae: 2.6105 - val_loss: 14.1551 - val_mae: 2.7920\n",
      "Epoch 6/25\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 14.0856 - mae: 2.3842 - val_loss: 14.9042 - val_mae: 2.9016\n",
      "Epoch 7/25\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 12.6397 - mae: 2.3684 - val_loss: 12.4676 - val_mae: 2.6228\n",
      "Epoch 8/25\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 12.4332 - mae: 2.2973 - val_loss: 12.2371 - val_mae: 2.6608\n",
      "Epoch 9/25\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 11.4608 - mae: 2.2178 - val_loss: 13.8007 - val_mae: 2.8781\n",
      "Epoch 10/25\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 11.8380 - mae: 2.2029 - val_loss: 11.8413 - val_mae: 2.6282\n",
      "Epoch 11/25\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 11.1257 - mae: 2.1606 - val_loss: 13.6088 - val_mae: 2.8031\n",
      "Epoch 12/25\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 11.1552 - mae: 2.1474 - val_loss: 13.2003 - val_mae: 2.8032\n",
      "Epoch 13/25\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 10.4849 - mae: 2.1085 - val_loss: 11.9528 - val_mae: 2.6402\n",
      "Epoch 14/25\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 10.1962 - mae: 2.0996 - val_loss: 11.2136 - val_mae: 2.5623\n",
      "Epoch 15/25\n",
      "303/303 [==============================] - 0s 2ms/step - loss: 9.3184 - mae: 2.0793 - val_loss: 10.1790 - val_mae: 2.4233\n",
      "Epoch 16/25\n",
      "303/303 [==============================] - 0s 2ms/step - loss: 9.8927 - mae: 2.0454 - val_loss: 11.3987 - val_mae: 2.5668\n",
      "Epoch 17/25\n",
      "303/303 [==============================] - 1s 2ms/step - loss: 9.4127 - mae: 2.0266 - val_loss: 10.8928 - val_mae: 2.4830\n",
      "Epoch 18/25\n",
      "303/303 [==============================] - 0s 2ms/step - loss: 9.5494 - mae: 2.0628 - val_loss: 13.2271 - val_mae: 2.8260\n",
      "Epoch 19/25\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 9.4935 - mae: 1.9954 - val_loss: 11.0578 - val_mae: 2.4964\n",
      "Epoch 20/25\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 9.0467 - mae: 1.9969 - val_loss: 12.3767 - val_mae: 2.6799\n",
      "Epoch 21/25\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 8.8894 - mae: 1.8979 - val_loss: 16.3787 - val_mae: 3.0866\n",
      "Epoch 22/25\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 8.6555 - mae: 1.9323 - val_loss: 9.8021 - val_mae: 2.3335\n",
      "Epoch 23/25\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 9.2412 - mae: 1.8968 - val_loss: 11.2402 - val_mae: 2.5471\n",
      "Epoch 24/25\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 8.8727 - mae: 1.8805 - val_loss: 11.0579 - val_mae: 2.4725\n",
      "Epoch 25/25\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 8.7397 - mae: 1.9327 - val_loss: 11.2431 - val_mae: 2.5670\n",
      "Processing fold 3\n",
      "Epoch 1/25\n",
      "303/303 [==============================] - 1s 2ms/step - loss: 197.3876 - mae: 10.3725 - val_loss: 28.2174 - val_mae: 3.5959\n",
      "Epoch 2/25\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 26.9088 - mae: 3.5883 - val_loss: 21.0877 - val_mae: 3.0782\n",
      "Epoch 3/25\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 18.9813 - mae: 2.9829 - val_loss: 17.9563 - val_mae: 2.9144\n",
      "Epoch 4/25\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 14.9930 - mae: 2.6998 - val_loss: 15.9364 - val_mae: 2.4754\n",
      "Epoch 5/25\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 13.6410 - mae: 2.5586 - val_loss: 16.4365 - val_mae: 2.5528\n",
      "Epoch 6/25\n",
      "303/303 [==============================] - 0s 2ms/step - loss: 12.1479 - mae: 2.4159 - val_loss: 15.6017 - val_mae: 2.5842\n",
      "Epoch 7/25\n",
      "303/303 [==============================] - 0s 2ms/step - loss: 10.8592 - mae: 2.2744 - val_loss: 14.4460 - val_mae: 2.4162\n",
      "Epoch 8/25\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 10.7371 - mae: 2.2578 - val_loss: 16.5525 - val_mae: 2.7201\n",
      "Epoch 9/25\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 9.7721 - mae: 2.1868 - val_loss: 15.7689 - val_mae: 2.6337\n",
      "Epoch 10/25\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 9.4492 - mae: 2.1530 - val_loss: 14.6135 - val_mae: 2.3969\n",
      "Epoch 11/25\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 9.0238 - mae: 2.0818 - val_loss: 18.4630 - val_mae: 2.8988\n",
      "Epoch 12/25\n",
      "303/303 [==============================] - 0s 2ms/step - loss: 8.7068 - mae: 2.0165 - val_loss: 14.8270 - val_mae: 2.4763\n",
      "Epoch 13/25\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 9.0711 - mae: 2.1580 - val_loss: 15.3332 - val_mae: 2.6416\n",
      "Epoch 14/25\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 8.5875 - mae: 2.0591 - val_loss: 16.4472 - val_mae: 2.6718\n",
      "Epoch 15/25\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 8.4029 - mae: 2.0491 - val_loss: 15.5994 - val_mae: 2.5148\n",
      "Epoch 16/25\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 8.3711 - mae: 2.0097 - val_loss: 14.0784 - val_mae: 2.4866\n",
      "Epoch 17/25\n",
      "303/303 [==============================] - 1s 2ms/step - loss: 8.2078 - mae: 1.9919 - val_loss: 15.1705 - val_mae: 2.5327\n",
      "Epoch 18/25\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 8.1443 - mae: 1.9888 - val_loss: 14.7523 - val_mae: 2.6385\n",
      "Epoch 19/25\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 7.8417 - mae: 1.9100 - val_loss: 15.2367 - val_mae: 2.6142\n",
      "Epoch 20/25\n",
      "303/303 [==============================] - 1s 2ms/step - loss: 7.2895 - mae: 1.9417 - val_loss: 15.2747 - val_mae: 2.6643\n",
      "Epoch 21/25\n",
      "303/303 [==============================] - 0s 2ms/step - loss: 7.8668 - mae: 1.8986 - val_loss: 15.8753 - val_mae: 2.5614\n",
      "Epoch 22/25\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 7.6078 - mae: 1.9348 - val_loss: 13.9576 - val_mae: 2.3944\n",
      "Epoch 23/25\n",
      "303/303 [==============================] - 0s 2ms/step - loss: 7.1119 - mae: 1.8858 - val_loss: 14.5314 - val_mae: 2.5814\n",
      "Epoch 24/25\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 6.8200 - mae: 1.8296 - val_loss: 14.8685 - val_mae: 2.5840\n",
      "Epoch 25/25\n",
      "303/303 [==============================] - 1s 2ms/step - loss: 7.0672 - mae: 1.8340 - val_loss: 14.6611 - val_mae: 2.6377\n",
      "Processing fold 4\n",
      "Epoch 1/25\n",
      "303/303 [==============================] - 1s 2ms/step - loss: 197.2056 - mae: 10.6663 - val_loss: 56.8360 - val_mae: 5.3713\n",
      "Epoch 2/25\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 25.3105 - mae: 3.4234 - val_loss: 39.6091 - val_mae: 4.1638\n",
      "Epoch 3/25\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 18.9395 - mae: 2.9317 - val_loss: 33.1381 - val_mae: 3.6501\n",
      "Epoch 4/25\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 16.2383 - mae: 2.6485 - val_loss: 27.7167 - val_mae: 3.2758\n",
      "Epoch 5/25\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 13.8978 - mae: 2.4691 - val_loss: 25.9348 - val_mae: 3.2127\n",
      "Epoch 6/25\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 13.1123 - mae: 2.3529 - val_loss: 23.2065 - val_mae: 3.0096\n",
      "Epoch 7/25\n",
      "303/303 [==============================] - 1s 2ms/step - loss: 12.2882 - mae: 2.2939 - val_loss: 25.4835 - val_mae: 3.0954\n",
      "Epoch 8/25\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 11.6076 - mae: 2.2965 - val_loss: 19.6273 - val_mae: 2.8142\n",
      "Epoch 9/25\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 11.2517 - mae: 2.2276 - val_loss: 22.9404 - val_mae: 3.0153\n",
      "Epoch 10/25\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 11.2037 - mae: 2.1737 - val_loss: 17.3542 - val_mae: 2.6847\n",
      "Epoch 11/25\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 10.6808 - mae: 2.1345 - val_loss: 18.8999 - val_mae: 2.8090\n",
      "Epoch 12/25\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 9.9738 - mae: 2.0656 - val_loss: 16.0321 - val_mae: 2.5727\n",
      "Epoch 13/25\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 9.5572 - mae: 2.0178 - val_loss: 18.7692 - val_mae: 2.7134\n",
      "Epoch 14/25\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 9.5056 - mae: 2.0358 - val_loss: 17.8074 - val_mae: 2.7329\n",
      "Epoch 15/25\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 9.8779 - mae: 2.0322 - val_loss: 16.1563 - val_mae: 2.5256\n",
      "Epoch 16/25\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 9.7192 - mae: 2.0512 - val_loss: 18.5198 - val_mae: 2.6937\n",
      "Epoch 17/25\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 9.0809 - mae: 1.9929 - val_loss: 16.3353 - val_mae: 2.5528\n",
      "Epoch 18/25\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 8.6678 - mae: 1.9027 - val_loss: 16.4290 - val_mae: 2.6639\n",
      "Epoch 19/25\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 8.9557 - mae: 1.9946 - val_loss: 18.0018 - val_mae: 2.9998\n",
      "Epoch 20/25\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 8.9640 - mae: 1.9478 - val_loss: 14.5909 - val_mae: 2.4318\n",
      "Epoch 21/25\n",
      "303/303 [==============================] - 1s 2ms/step - loss: 8.6178 - mae: 1.9391 - val_loss: 15.6606 - val_mae: 2.4876\n",
      "Epoch 22/25\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 7.7728 - mae: 1.8762 - val_loss: 15.8898 - val_mae: 2.6369\n",
      "Epoch 23/25\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 8.0324 - mae: 1.8593 - val_loss: 12.8822 - val_mae: 2.3467\n",
      "Epoch 24/25\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 8.1136 - mae: 1.8930 - val_loss: 14.0484 - val_mae: 2.4455\n",
      "Epoch 25/25\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 8.0182 - mae: 1.8112 - val_loss: 13.6461 - val_mae: 2.3673\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# ? It's possible that there's been an error if any cell is run twice.\n",
    "# ? Attempted fix is resetting arrays.\n",
    "allMAEHistories = []\n",
    "allMAEHistoriesTrain = []\n",
    "\n",
    "kFold(k = 4, numEpochs = 25)\n",
    "# ? 200 epochs was specified in the lab sheet but it takes approx 5min30sec."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
